{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The k-fold cross-validation procedure is a standard method for estimating the performance of a machine learning algorithm or configuration on a dataset.\n",
    "\n",
    "A single run of the k-fold cross-validation procedure may result in a noisy estimate of model performance. Different splits of the data may result in very different results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variations on Cross-Validation\n",
    "There are a number of variations on the k-fold cross validation procedure.\n",
    "\n",
    "Three commonly used variations are as follows:\n",
    "\n",
    "**Train/Test Split**: Taken to one extreme, k may be set to 2 (not 1) such that a single train/test split is created to evaluate the model.\n",
    "\n",
    "**LOOCV**: Taken to another extreme, k may be set to the total number of observations in the dataset such that each observation is given a chance to be the held out of the dataset. This is called leave-one-out cross-validation, or LOOCV for short.\n",
    "\n",
    "**Stratified**: The splitting of data into folds may be governed by criteria such as ensuring that each fold has the same proportion of observations with a given categorical value, such as the class outcome value. This is called stratified cross-validation.\n",
    "\n",
    "**Repeated**: This is where the k-fold cross-validation procedure is repeated n times, where importantly, the data sample is shuffled prior to each repetition, which results in a different split of the sample.\n",
    "\n",
    "**Nested**: This is where k-fold cross-validation is performed within each fold of cross-validation, often to perform hyperparameter tuning during model evaluation. This is called nested cross-validation or double cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_classification(n_samples=1000, n_features=20, n_informative=15, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 20) (1000,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=5, random_state=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KFold(n_splits=5, random_state=1, shuffle=True)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kfold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf  = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(clf, X, y, scoring='accuracy', cv= kfold, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.865, 0.88 , 0.865, 0.87 , 0.85 ])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean of accuracy 0.866 \n",
      "std of accuracy 0.009695359714832668\n"
     ]
    }
   ],
   "source": [
    "print(\"mean of accuracy\",mean(scores),\"\\nstd of accuracy\",std(scores)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean of accuracy 87.0 \n",
      "std of accuracy 1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"mean of accuracy\",round(mean(scores),2)*100,\"\\nstd of accuracy\",round(std(scores),2)*100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(rf, X, y, scoring='accuracy', cv= kfold, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.93, 0.92, 0.94, 0.95, 0.91, 0.9 , 0.86, 0.9 , 0.92, 0.9 ])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean of accuracy 91.0 \n",
      "std of accuracy 2.0\n"
     ]
    }
   ],
   "source": [
    "print(\"mean of accuracy\",round(mean(scores),2)*100,\"\\nstd of accuracy\",round(std(scores),2)*100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Repeated KFOLD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    The estimate of model performance via k-fold cross-validation can be noisy.\n",
    "    This means that each time the procedure is run, a different split of the dataset into k-folds can be implemented, and in turn, the distribution of performance scores can be different, resulting in a different mean estimate of model performance.\n",
    "    A noisy estimate of model performance can be frustrating as it may not be clear which result should be used to compare and select a final model to address the problem.\n",
    "    One solution to reduce the noise in the estimated model performance is to increase the k-value. This will reduce the bias in the modelâ€™s estimated performance, although it will increase the variance: e.g. tie the result more to the specific dataset used in the evaluation.\n",
    "    Repeated k-fold cross-validation has the benefit of improving the estimate of the mean model performance at the cost of fitting and evaluating many more models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean of accuracy 87.0 \n",
      "std of accuracy 4.0\n"
     ]
    }
   ],
   "source": [
    "X, y = make_classification(n_samples=1000, n_features=20, n_informative=15, random_state=1)\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "Rkfold = RepeatedKFold(n_splits=10, n_repeats= 3, random_state=1)\n",
    "scores = cross_val_score(clf, X, y, scoring='accuracy', cv= Rkfold, n_jobs=-1)\n",
    "print(\"mean of accuracy\",round(mean(scores),2)*100,\"\\nstd of accuracy\",round(std(scores),2)*100) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  stratified k-fold cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "k-Fold Cross-Validation for Imbalanced Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Imbalanced Dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=2, n_redundant=0, n_clusters_per_class=1, weights=[0.9], flip_y=0, random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import unique\n",
    "classes = unique(y)\n",
    "total = len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Class=0 : 901/1000 (90.1%)\n",
      ">Class=1 : 99/1000 (9.9%)\n"
     ]
    }
   ],
   "source": [
    "for c in classes:\n",
    "    n_examples = len(y[y==c])\n",
    "    percent = n_examples/total *100\n",
    "    print('>Class=%d : %d/%d (%.1f%%)' % (c, n_examples, total, percent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "## use the KFold class to randomly split the dataset into 5-folds and check the composition of each train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Train: 0=716, 1=84, Test:0=185, 1=15\n",
      ">Train: 0=728, 1=72, Test:0=173, 1=27\n",
      ">Train: 0=722, 1=78, Test:0=179, 1=21\n",
      ">Train: 0=718, 1=82, Test:0=183, 1=17\n",
      ">Train: 0=720, 1=80, Test:0=181, 1=19\n"
     ]
    }
   ],
   "source": [
    "kfold = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "for train,test in kfold.split(X):\n",
    "    # Select ROWS\n",
    "    train_X, test_X = X[train], X[test]\n",
    "    train_y, test_y = y[train], y[test]\n",
    "    \n",
    "    # Summarize train and test\n",
    "    train_0 , train_1 = len(train_y[train_y==0]), len(train_y[train_y==1])\n",
    "    test_0, test_1 = len(test_y[test_y==0]), len(test_y[test_y==1]) \n",
    "    \n",
    "    print('>Train: 0=%d, 1=%d, Test:0=%d, 1=%d' % (train_0, train_1, test_0, test_1))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "skfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Train: 0=720, 1=80, Test:0=181, 1=19\n",
      ">Train: 0=721, 1=79, Test:0=180, 1=20\n",
      ">Train: 0=721, 1=79, Test:0=180, 1=20\n",
      ">Train: 0=721, 1=79, Test:0=180, 1=20\n",
      ">Train: 0=721, 1=79, Test:0=180, 1=20\n"
     ]
    }
   ],
   "source": [
    "for train,test in skfold.split(X,y):\n",
    "    # Select ROWS\n",
    "    train_X, test_X = X[train], X[test]\n",
    "    train_y, test_y = y[train], y[test]\n",
    "    \n",
    "    # Summarize train and test\n",
    "    train_0 , train_1 = len(train_y[train_y==0]), len(train_y[train_y==1])\n",
    "    test_0, test_1 = len(test_y[test_y==0]), len(test_y[test_y==1]) \n",
    "    \n",
    "    print('>Train: 0=%d, 1=%d, Test:0=%d, 1=%d' % (train_0, train_1, test_0, test_1))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sss = StratifiedShuffleSplit(n_splits=5, test_size=0.3, random_state=0)\n",
    "sss.get_n_splits(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Train: 0=631, 1=69, Test:0=270, 1=30\n",
      ">Train: 0=631, 1=69, Test:0=270, 1=30\n",
      ">Train: 0=631, 1=69, Test:0=270, 1=30\n",
      ">Train: 0=631, 1=69, Test:0=270, 1=30\n",
      ">Train: 0=631, 1=69, Test:0=270, 1=30\n"
     ]
    }
   ],
   "source": [
    "for train,test in sss.split(X,y):\n",
    "    # Select ROWS\n",
    "    train_X, test_X = X[train], X[test]\n",
    "    train_y, test_y = y[train], y[test]\n",
    "    \n",
    "    # Summarize train and test\n",
    "    train_0 , train_1 = len(train_y[train_y==0]), len(train_y[train_y==1])\n",
    "    test_0, test_1 = len(test_y[test_y==0]), len(test_y[test_y==1]) \n",
    "    \n",
    "    print('>Train: 0=%d, 1=%d, Test:0=%d, 1=%d' % (train_0, train_1, test_0, test_1))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

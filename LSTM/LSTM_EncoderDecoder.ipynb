{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPKK232NaqD8ueGatyQH3U1"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":[],"metadata":{"id":"kfTZ_spsxSjW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Input, LSTM, Dense\n","from tensorflow.keras.optimizers import Adam\n","\n","# Generate a dataset\n","def generate_sequence(length, num_sequences):\n","    return np.array([np.arange(i, i + length) for i in range(num_sequences)])\n","\n","# Parameters\n","sequence_length = 5\n","num_sequences = 1000\n","\n","# Create sequences\n","sequences = generate_sequence(sequence_length, num_sequences)"],"metadata":{"id":"EiGJHPIgxTLH","executionInfo":{"status":"ok","timestamp":1719241391216,"user_tz":-330,"elapsed":428,"user":{"displayName":"sahil mattoo","userId":"12677670215088693742"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["sequences"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d37lWqmkxaMV","executionInfo":{"status":"ok","timestamp":1719241391626,"user_tz":-330,"elapsed":5,"user":{"displayName":"sahil mattoo","userId":"12677670215088693742"}},"outputId":"acbdceeb-d05b-4b1c-dc29-d12796172605"},"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[   0,    1,    2,    3,    4],\n","       [   1,    2,    3,    4,    5],\n","       [   2,    3,    4,    5,    6],\n","       ...,\n","       [ 997,  998,  999, 1000, 1001],\n","       [ 998,  999, 1000, 1001, 1002],\n","       [ 999, 1000, 1001, 1002, 1003]])"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["# Prepare the data\n","X = sequences[:, :-1]\n","y = sequences[:, 1:]"],"metadata":{"id":"Vv8wjC0FxTQA","executionInfo":{"status":"ok","timestamp":1719241395700,"user_tz":-330,"elapsed":2,"user":{"displayName":"sahil mattoo","userId":"12677670215088693742"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["X"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OxvCu-h7xeBX","executionInfo":{"status":"ok","timestamp":1719241404836,"user_tz":-330,"elapsed":4,"user":{"displayName":"sahil mattoo","userId":"12677670215088693742"}},"outputId":"f5fd2ed0-354a-4cc2-d964-f7479bdc56df"},"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[   0,    1,    2,    3],\n","       [   1,    2,    3,    4],\n","       [   2,    3,    4,    5],\n","       ...,\n","       [ 997,  998,  999, 1000],\n","       [ 998,  999, 1000, 1001],\n","       [ 999, 1000, 1001, 1002]])"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["y"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VkXsYrPYxgN-","executionInfo":{"status":"ok","timestamp":1719241413392,"user_tz":-330,"elapsed":4,"user":{"displayName":"sahil mattoo","userId":"12677670215088693742"}},"outputId":"f66977fa-e3fe-4b69-8257-5d7c809a2820"},"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[   1,    2,    3,    4],\n","       [   2,    3,    4,    5],\n","       [   3,    4,    5,    6],\n","       ...,\n","       [ 998,  999, 1000, 1001],\n","       [ 999, 1000, 1001, 1002],\n","       [1000, 1001, 1002, 1003]])"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["# Reshape for LSTM [samples, time steps, features]\n","X = X.reshape((X.shape[0], X.shape[1], 1))\n","y = y.reshape((y.shape[0], y.shape[1], 1))\n"],"metadata":{"id":"Sek2I-b9xkcl","executionInfo":{"status":"ok","timestamp":1719241430699,"user_tz":-330,"elapsed":418,"user":{"displayName":"sahil mattoo","userId":"12677670215088693742"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["X"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7swTvq2rxlzA","executionInfo":{"status":"ok","timestamp":1719241435081,"user_tz":-330,"elapsed":6,"user":{"displayName":"sahil mattoo","userId":"12677670215088693742"}},"outputId":"8e4d528b-5d43-4f49-9743-01572791818a"},"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[[   0],\n","        [   1],\n","        [   2],\n","        [   3]],\n","\n","       [[   1],\n","        [   2],\n","        [   3],\n","        [   4]],\n","\n","       [[   2],\n","        [   3],\n","        [   4],\n","        [   5]],\n","\n","       ...,\n","\n","       [[ 997],\n","        [ 998],\n","        [ 999],\n","        [1000]],\n","\n","       [[ 998],\n","        [ 999],\n","        [1000],\n","        [1001]],\n","\n","       [[ 999],\n","        [1000],\n","        [1001],\n","        [1002]]])"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":["y"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3_1qqK__xsY5","executionInfo":{"status":"ok","timestamp":1719241462115,"user_tz":-330,"elapsed":2,"user":{"displayName":"sahil mattoo","userId":"12677670215088693742"}},"outputId":"a2b6299e-56fe-4891-fe8b-2a9135cbbc42"},"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[[   1],\n","        [   2],\n","        [   3],\n","        [   4]],\n","\n","       [[   2],\n","        [   3],\n","        [   4],\n","        [   5]],\n","\n","       [[   3],\n","        [   4],\n","        [   5],\n","        [   6]],\n","\n","       ...,\n","\n","       [[ 998],\n","        [ 999],\n","        [1000],\n","        [1001]],\n","\n","       [[ 999],\n","        [1000],\n","        [1001],\n","        [1002]],\n","\n","       [[1000],\n","        [1001],\n","        [1002],\n","        [1003]]])"]},"metadata":{},"execution_count":14}]},{"cell_type":"markdown","source":["None: This dimension represents the time steps of the input sequences. Setting it to **None** means that the length of the input sequences can vary. This makes the model flexible to handle input sequences of different lengths. In sequence-to-sequence models, the length of the input sequence can vary depending on the specific application or dataset.\n","\n","\n","1: This dimension represents the number of features at each time step. Here **1** indicates that at each time step, there is only one feature. This is because our data consists of single numerical values (e.g., a sequence of numbers)."],"metadata":{"id":"G6_WKN-I0kwv"}},{"cell_type":"markdown","source":["# Encoder"],"metadata":{"id":"L-xdHm9c2ocI"}},{"cell_type":"code","source":["# Encoder\n","encoder_inputs = Input(shape=(None, 1))\n","encoder_lstm = LSTM(50, return_state=True)\n","encoder_outputs, state_h, state_c = encoder_lstm(encoder_inputs)\n","encoder_states = [state_h, state_c]"],"metadata":{"id":"YXG04lMw2rmA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Decoder"],"metadata":{"id":"sF42H27v2ukV"}},{"cell_type":"code","source":["# Decoder\n","decoder_inputs = Input(shape=(None, 1))\n","decoder_lstm = LSTM(50, return_sequences=True, return_state=True)\n","decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n","decoder_dense = Dense(1)\n","decoder_outputs = decoder_dense(decoder_outputs)"],"metadata":{"id":"JVWyjpIm2wxO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["The Dense(1) layer in the decoder part of an LSTM Encoder-Decoder model is used to transform the high-dimensional output from the LSTM to a single value per time step.\n","\n","This transformation is necessary to match the desired output shape, where each time step in the output sequence corresponds to a single predicted value.\n","\n","It simplifies the task of the model by focusing on generating the final predicted values in the appropriate format."],"metadata":{"id":"tVtDYNhy35ZL"}},{"cell_type":"code","source":["# Prepare decoder input data, which is just the shifted output sequences\n","decoder_input_data = np.zeros_like(y)\n","decoder_input_data[:, 1:, :] = y[:, :-1, :]\n","decoder_input_data"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"p6MTd0HE4RlO","executionInfo":{"status":"ok","timestamp":1719243193317,"user_tz":-330,"elapsed":545,"user":{"displayName":"sahil mattoo","userId":"12677670215088693742"}},"outputId":"40e139f6-9c98-4812-fb21-18ffb15a711c"},"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[[   0],\n","        [   1],\n","        [   2],\n","        [   3]],\n","\n","       [[   0],\n","        [   2],\n","        [   3],\n","        [   4]],\n","\n","       [[   0],\n","        [   3],\n","        [   4],\n","        [   5]],\n","\n","       ...,\n","\n","       [[   0],\n","        [ 998],\n","        [ 999],\n","        [1000]],\n","\n","       [[   0],\n","        [ 999],\n","        [1000],\n","        [1001]],\n","\n","       [[   0],\n","        [1000],\n","        [1001],\n","        [1002]]])"]},"metadata":{},"execution_count":17}]},{"cell_type":"code","source":["# Define the model\n","model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"],"metadata":{"id":"rcRqjLH67fHw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Input Tensors:** It takes both **encoder_inputs** and **decoder_inputs** as the inputs to the model.\n","This helps the model to learn the mapping from input sequences (encoder inputs) to output sequences (decoder outputs) with the help of decoder inputs during training.\n","\n","\n","**Output Tensor:** The decoder_outputs tensor is the output of the model, representing the predicted sequence."],"metadata":{"id":"iVb9Kqji7HHz"}},{"cell_type":"code","source":["# Compile the model\n","model.compile(optimizer=Adam(), loss='mse')"],"metadata":{"id":"_LLykAn37iFT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Training parameters\n","epochs = 20\n","batch_size = 64\n","\n","\n","# Train the model\n","history = model.fit([X, decoder_input_data], y, epochs=epochs, batch_size=batch_size, validation_split=0.2)\n"],"metadata":{"id":"YZAwAeJm8Mgq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**X:** This is the input data for the encoder.\n","It consists of sequences that the encoder will process. Its shape is (samples, time_steps, features):\n","\n","**samples** is the number of sequences.\n","\n","**time_steps** is the length of each sequence.\n","\n","**features** is the number of features per time step (usually 1 in simple sequence tasks).\n","\n","\n","**Role:** The encoder processes these sequences to compress the information into a context vector (a set of states), which captures the input sequence's important features. This **context vector** is then passed to the decoder as its initial state.\n","\n","**decoder_input_data** contains the sequences fed into the decoder during training.\n","\n","During training, the decoder requires input sequences to learn the mapping from encoder outputs to the target sequences. These inputs are usually the ground truth shifted by one time step.\n","\n","**Teacher Forcing:** This technique, known as teacher forcing, involves using the actual target sequence as the input to the decoder at each time step. This helps the model learn to predict the next time step more effectively.\n","\n","\n","**WORKING**\n","\n","Training with Encoder and Decoder:\n","\n","During training, the model learns to map input sequences to output sequences.\n","\n","**Encoder:** The encoder takes X as input and processes it through its LSTM layers, resulting in a set of states (hidden state and cell state). These states encapsulate the information from the input sequence.\n","\n","**Decoder:** The decoder takes two inputs during training:\n","Initial States: The states generated by the encoder.\n","\n","**Input Sequences:** decoder_input_data, which are sequences that help the decoder learn the correct mapping to the target sequences.\n","\n","\n","**What if we use only X ??**\n","\n","If we only used X, the model would have no way of knowing the actual sequence\n","it is supposed to generate during training.\n","The decoder needs **guidance** in the form of **decoder_input_data** to learn the correct sequence.\n","\n","The encoder compresses the input sequence into states, but the decoder still needs the sequence context provided by decoder_input_data to predict the next elements in the sequence correctly.\n"],"metadata":{"id":"fw6BoLsG8KNx"}},{"cell_type":"markdown","source":["# INFERENCE"],"metadata":{"id":"RttKbp1oEPkN"}},{"cell_type":"code","source":["# Define encoder model\n","encoder_model = Model(encoder_inputs, encoder_states)"],"metadata":{"id":"iamPXi1nCKcX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["encoder_model is used for Inference\n","\n","The primary function of the encoder during inference is to convert the input sequence into a set of initial states (hidden state and cell state) for the decoder."],"metadata":{"id":"mUelnTRYCm0i"}},{"cell_type":"markdown","source":["# Decoder State Inputs"],"metadata":{"id":"cozljNbLE653"}},{"cell_type":"code","source":["# Define decoder model\n","decoder_state_input_h = Input(shape=(50,))\n","decoder_state_input_c = Input(shape=(50,))\n","decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]"],"metadata":{"id":"zRhbYOzcEoks"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["placeholders for the decoder's initial states (hidden state and cell state) during inference.\n","\n","\n","The decoder requires the initial states from the encoder to start generating the output sequence. These placeholders will be filled with the actual state values during each step of the inference process.\n"],"metadata":{"id":"t9ymyAynEqIe"}},{"cell_type":"code","source":["decoder_outputs, state_h, state_c = decoder_lstm(\n","    decoder_inputs, initial_state=decoder_states_inputs)"],"metadata":{"id":"kgFsJqqCD1r_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["During each step of inference, the decoder takes the current input and the previous states to produce the next output and update the states.\n","\n","By specifying **initial_state=decoder_states_inputs**, we allow the LSTM to use the provided states as its starting point."],"metadata":{"id":"-rlc0sw3FE60"}},{"cell_type":"code","source":["decoder_states = [state_h, state_c]\n","decoder_outputs = decoder_dense(decoder_outputs)"],"metadata":{"id":"-Rh3cz8GFSvM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Purpose**: This line groups the updated states into a list. These updated states will be fed back into the decoder in the next time step.\n","\n","\n","**Explanation**: The states need to be updated after each time step to accurately reflect the context of the sequence generated so far. This list of updated states will be used as the initial state for the next decoding step."],"metadata":{"id":"t9MEt_igFcMf"}},{"cell_type":"code","source":["decoder_model = Model(\n","    [decoder_inputs] + decoder_states_inputs,\n","    [decoder_outputs] + decoder_states)"],"metadata":{"id":"3naLwogzD-JD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["The decoder model for inference in a sequence-to-sequence LSTM\n","\n","**[decoder_inputs] + decoder_states_inputs** --> Input to Decoder Model\n","\n","By concatenating **[decoder_inputs] and decoder_states_inputs**, it is specified all the inputs required for the decoder model to start generating the output sequence.\n","\n","\n","**[decoder_outputs] + decoder_states** --> Output from Model\n","\n","By concatenating **[decoder_outputs] and decoder_states**, we specify all the outputs returned by the decoder model after processing the input sequence."],"metadata":{"id":"3m7kIGyWF3Yy"}},{"cell_type":"markdown","source":["**During training**, the decoder is part of the larger model that includes the encoder and is trained end-to-end.\n","\n","\n","**During inference**, however, we need a separate model that can generate sequences based on previously unseen inputs and states.\n","\n","\n","**The decoder_model** allows us to initialize the LSTM states (decoder_states_inputs) and update them (decoder_states) across multiple time steps as the sequence is generated.\n","\n","\n","This stateful nature ensures that the context of the sequence is preserved and contributes to accurate sequence generation."],"metadata":{"id":"pdk_Gar6FoTr"}},{"cell_type":"code","source":["\n","\n","\n","\n","\n","# Function to predict the next sequence\n","def predict_sequence(input_seq):\n","    # Encode the input as state vectors.\n","    states_value = encoder_model.predict(input_seq)\n","\n","    # Generate empty target sequence of length 1.\n","    target_seq = np.zeros((1, 1, 1))\n","    # Populate the first value of target sequence with the first value of input sequence.\n","    target_seq[0, 0, 0] = input_seq[0, 0, 0] + 1\n","\n","    # Sampling loop for a batch of sequences\n","    stop_condition = False\n","    decoded_seq = []\n","\n","    while not stop_condition:\n","        output_tokens, h, c = decoder_model.predict(\n","            [target_seq] + states_value)\n","\n","        # Sample a token\n","        sampled_token = output_tokens[0, -1, 0]\n","        decoded_seq.append(sampled_token)\n","\n","        # Exit condition: either hit max length\n","        if len(decoded_seq) == sequence_length - 1:\n","            stop_condition = True\n","\n","        # Update the target sequence (of length 1).\n","        target_seq = np.zeros((1, 1, 1))\n","        target_seq[0, 0, 0] = sampled_token\n","\n","        # Update states\n","        states_value = [h, c]\n","\n","    return decoded_seq\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"S5rOrOOzsGTN","executionInfo":{"status":"ok","timestamp":1719241497661,"user_tz":-330,"elapsed":15822,"user":{"displayName":"sahil mattoo","userId":"12677670215088693742"}},"outputId":"780116d0-0770-4e30-c1e4-aa61ab3499d2"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","13/13 [==============================] - 8s 218ms/step - loss: 215034.9219 - val_loss: 815929.6250\n","Epoch 2/20\n","13/13 [==============================] - 0s 10ms/step - loss: 214076.9531 - val_loss: 814229.2500\n","Epoch 3/20\n","13/13 [==============================] - 0s 10ms/step - loss: 213306.8438 - val_loss: 812552.9375\n","Epoch 4/20\n","13/13 [==============================] - 0s 11ms/step - loss: 212560.0781 - val_loss: 810224.8125\n","Epoch 5/20\n","13/13 [==============================] - 0s 10ms/step - loss: 211485.5156 - val_loss: 808275.6250\n","Epoch 6/20\n","13/13 [==============================] - 0s 12ms/step - loss: 210376.5625 - val_loss: 805196.3750\n","Epoch 7/20\n","13/13 [==============================] - 0s 10ms/step - loss: 208821.4062 - val_loss: 801456.5000\n","Epoch 8/20\n","13/13 [==============================] - 0s 10ms/step - loss: 207008.6562 - val_loss: 797556.8750\n","Epoch 9/20\n","13/13 [==============================] - 0s 10ms/step - loss: 205778.7656 - val_loss: 794927.6250\n","Epoch 10/20\n","13/13 [==============================] - 0s 10ms/step - loss: 204375.2031 - val_loss: 791670.5625\n","Epoch 11/20\n","13/13 [==============================] - 0s 11ms/step - loss: 203088.9844 - val_loss: 788922.1875\n","Epoch 12/20\n","13/13 [==============================] - 0s 10ms/step - loss: 202244.2031 - val_loss: 787260.1875\n","Epoch 13/20\n","13/13 [==============================] - 0s 12ms/step - loss: 201385.2656 - val_loss: 785300.7500\n","Epoch 14/20\n","13/13 [==============================] - 0s 11ms/step - loss: 200512.7812 - val_loss: 783163.7500\n","Epoch 15/20\n","13/13 [==============================] - 0s 10ms/step - loss: 199729.0156 - val_loss: 781393.1875\n","Epoch 16/20\n","13/13 [==============================] - 0s 10ms/step - loss: 198999.2812 - val_loss: 779673.6875\n","Epoch 17/20\n","13/13 [==============================] - 0s 9ms/step - loss: 198279.8594 - val_loss: 778194.8125\n","Epoch 18/20\n","13/13 [==============================] - 0s 10ms/step - loss: 197647.5156 - val_loss: 776744.2500\n","Epoch 19/20\n","13/13 [==============================] - 0s 11ms/step - loss: 197031.0781 - val_loss: 775326.9375\n","Epoch 20/20\n","13/13 [==============================] - 0s 13ms/step - loss: 196427.9531 - val_loss: 773940.9375\n"]}]},{"cell_type":"code","source":["# Test the prediction\n","test_seq = np.array([[0, 1, 2, 3]]).reshape((1, 4, 1))"],"metadata":{"id":"VfE4dflUsHs-","executionInfo":{"status":"ok","timestamp":1719241733249,"user_tz":-330,"elapsed":409,"user":{"displayName":"sahil mattoo","userId":"12677670215088693742"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["predicted_seq = predict_sequence(test_seq)\n","print(\"Input sequence:\", test_seq.flatten())\n","print(\"Predicted sequence:\", predicted_seq)\n"],"metadata":{"id":"gXDRx38VyvBH"},"execution_count":null,"outputs":[]}]}
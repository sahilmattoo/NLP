{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPic41v7DLDEcgVBj8JBa65"},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"b7DFNSwyfFuu"},"source":["Author: **Ramsri Goutham Golla**  [Linkedin](https://www.linkedin.com/in/ramsrig/)   [Twitter](https://twitter.com/ramsri_goutham/)\n","\n","\n","I recently launched  **Practical Introduction to NLP**, online course. \n","\n","If you are interested, please check out the **[syllabus and enroll.](https://www.learnnlp.academy/practical-introduction-to-natural-language-processing)**\n"]},{"cell_type":"markdown","metadata":{"id":"U5cJ3XAu86oT"},"source":["## Extract keywords from story"]},{"cell_type":"code","metadata":{"id":"WSlyy1u_9vA-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679112077345,"user_tz":-330,"elapsed":42505,"user":{"displayName":"Ramsri Goutham","userId":"00967418115712089730"}},"outputId":"1c0b27d1-4e3b-4b70-e4f2-9bf9dc2f025f"},"source":["# Installing from https://github.com/boudinfl/pke library for Python Keyword extraction\n","# We use a fixed commit as the later changes might break the code. If it was on pip we would have used exact version number.\n","\n","# !pip install --quiet git+https://github.com/boudinfl/pke.git@dc4d5f21e0ffe64c4df93c46146d29d1c522476b\n","# !pip install --quiet flashtext==2.7\n","\n","\n","!pip install --quiet flashtext==2.7\n","!pip install git+https://github.com/boudinfl/pke.git\n","!pip install tokenizers==0.9.4\n","!pip install sentencepiece==0.1.97\n","!pip install --no-dependencies transformers==2.9.0\n","# !pip install transformers==3.4.0\n","# !pip install transformers==4.1.0\n","# tokenizers-0.9.4\n","\n","# !pip install --quiet nltk==3.4.5"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for flashtext (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting git+https://github.com/boudinfl/pke.git\n","  Cloning https://github.com/boudinfl/pke.git to /tmp/pip-req-build-3z3r7ngj\n","  Running command git clone --filter=blob:none --quiet https://github.com/boudinfl/pke.git /tmp/pip-req-build-3z3r7ngj\n","  Resolved https://github.com/boudinfl/pke.git to commit f2d4f5d2252c64d23defccd32fdac8809cfd7ce0\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: nltk in /usr/local/lib/python3.9/dist-packages (from pke==2.0.0) (3.8.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from pke==2.0.0) (3.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from pke==2.0.0) (1.22.4)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (from pke==2.0.0) (1.10.1)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.9/dist-packages (from pke==2.0.0) (1.2.2)\n","Collecting unidecode\n","  Downloading Unidecode-1.3.6-py3-none-any.whl (235 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.9/235.9 KB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.9/dist-packages (from pke==2.0.0) (0.18.3)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.9/dist-packages (from pke==2.0.0) (1.1.1)\n","Requirement already satisfied: spacy>=3.2.3 in /usr/local/lib/python3.9/dist-packages (from pke==2.0.0) (3.5.1)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.9/dist-packages (from spacy>=3.2.3->pke==2.0.0) (3.0.12)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.9/dist-packages (from spacy>=3.2.3->pke==2.0.0) (4.65.0)\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from spacy>=3.2.3->pke==2.0.0) (1.0.4)\n","Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.9/dist-packages (from spacy>=3.2.3->pke==2.0.0) (8.1.9)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.9/dist-packages (from spacy>=3.2.3->pke==2.0.0) (2.0.8)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.9/dist-packages (from spacy>=3.2.3->pke==2.0.0) (2.27.1)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.9/dist-packages (from spacy>=3.2.3->pke==2.0.0) (1.10.6)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.9/dist-packages (from spacy>=3.2.3->pke==2.0.0) (2.4.6)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from spacy>=3.2.3->pke==2.0.0) (63.4.3)\n","Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.9/dist-packages (from spacy>=3.2.3->pke==2.0.0) (6.3.0)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from spacy>=3.2.3->pke==2.0.0) (3.0.8)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from spacy>=3.2.3->pke==2.0.0) (23.0)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from spacy>=3.2.3->pke==2.0.0) (3.1.2)\n","Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from spacy>=3.2.3->pke==2.0.0) (3.3.0)\n","Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.9/dist-packages (from spacy>=3.2.3->pke==2.0.0) (0.10.1)\n","Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.9/dist-packages (from spacy>=3.2.3->pke==2.0.0) (1.1.1)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.9/dist-packages (from spacy>=3.2.3->pke==2.0.0) (2.0.7)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.9/dist-packages (from spacy>=3.2.3->pke==2.0.0) (1.0.9)\n","Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.9/dist-packages (from spacy>=3.2.3->pke==2.0.0) (0.7.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.9/dist-packages (from nltk->pke==2.0.0) (8.1.3)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.9/dist-packages (from nltk->pke==2.0.0) (2022.10.31)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn->pke==2.0.0) (3.1.0)\n","Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.9/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy>=3.2.3->pke==2.0.0) (4.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3.2.3->pke==2.0.0) (2022.12.7)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3.2.3->pke==2.0.0) (3.4)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3.2.3->pke==2.0.0) (1.26.15)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3.2.3->pke==2.0.0) (2.0.12)\n","Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.9/dist-packages (from thinc<8.2.0,>=8.1.8->spacy>=3.2.3->pke==2.0.0) (0.0.4)\n","Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.9/dist-packages (from thinc<8.2.0,>=8.1.8->spacy>=3.2.3->pke==2.0.0) (0.7.9)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->spacy>=3.2.3->pke==2.0.0) (2.1.2)\n","Building wheels for collected packages: pke\n","  Building wheel for pke (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pke: filename=pke-2.0.0-py3-none-any.whl size=6160676 sha256=0a85eba33454df82e46a82dd4057f8dfb4f26623d39121ca66b539eaa5d6b6d8\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-h91js5v9/wheels/d5/46/97/85535b5b449f70b6a3c8d1138ce8587345876891e25bfe7954\n","Successfully built pke\n","Installing collected packages: unidecode, pke\n","Successfully installed pke-2.0.0 unidecode-1.3.6\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting tokenizers==0.9.4\n","  Downloading tokenizers-0.9.4-cp39-cp39-manylinux2010_x86_64.whl (2.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m41.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: tokenizers\n","Successfully installed tokenizers-0.9.4\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting sentencepiece==0.1.97\n","  Downloading sentencepiece-0.1.97-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: sentencepiece\n","Successfully installed sentencepiece-0.1.97\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers==2.9.0\n","  Downloading transformers-2.9.0-py3-none-any.whl (635 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m635.7/635.7 KB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: transformers\n","Successfully installed transformers-2.9.0\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iR6rMLaaM37X","executionInfo":{"status":"ok","timestamp":1679112104254,"user_tz":-330,"elapsed":23604,"user":{"displayName":"Ramsri Goutham","userId":"00967418115712089730"}},"outputId":"2c5a7c34-56ab-45d0-9d50-fd3e4432b3b4"},"source":["# connect your personal google drive to store the trained model\n","from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-bTE46mP-nYj","executionInfo":{"status":"ok","timestamp":1679112123918,"user_tz":-330,"elapsed":16949,"user":{"displayName":"Ramsri Goutham","userId":"00967418115712089730"}},"outputId":"99a6eb2a-03c3-4947-d7ba-4d32a2ca31ba"},"source":["import json\n","import requests\n","import string\n","import re\n","import nltk\n","import string\n","import itertools\n","nltk.download('stopwords')\n","nltk.download('wordnet')\n","nltk.download('punkt')\n","import pke\n","from nltk.corpus import stopwords\n","from nltk.corpus import wordnet\n","import traceback\n","from nltk.tokenize import sent_tokenize\n","from flashtext import KeywordProcessor\n","\n","def tokenize_sentences(text):\n","    sentences = sent_tokenize(text)\n","    sentences = [sentence.strip() for sentence in sentences if len(sentence) > 20]\n","    return sentences"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","/usr/local/lib/python3.9/dist-packages/torch/cuda/__init__.py:497: UserWarning: Can't initialize NVML\n","  warnings.warn(\"Can't initialize NVML\")\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mvZ2DG299ApF","executionInfo":{"status":"ok","timestamp":1679112125145,"user_tz":-330,"elapsed":9,"user":{"displayName":"Ramsri Goutham","userId":"00967418115712089730"}},"outputId":"4966fce3-5ad7-45a7-da03-020ef5c1e26b"},"source":["import textwrap\n","# Story source - https://byjus.com/kids-learning/moral-stories-the-lion-and-the-mouse/\n","\n","text = \"\"\" Once upon a time, there lived a lion in the dense Amazon rainforest. While he was sleeping by resting his big head on his paws, a tiny little mouse unexpectedly crossed by and ran across the lion’s nose in haste. This woke up the lion and he laid his huge paw angrily on the tiny mouse to kill her.\n","\n","The poor mouse begged the lion to spare her this time and she would pay him back on some other day. Hearing this, the lion was amused and wondered how could such a tiny creature ever help him. But he was in a good mood and in his generosity he finally let the mouse go.\n","\n","A few days later, a hunter set a trap for the lion while the big animal was stalking for prey in the forest. Caught in the toils of a hunter’s net, the lion found it difficult to free himself and roared loudly in anger.\n","\n","As the mouse was passing by, she heard the roar and found the lion struggling hard to free himself from the hunter’s net. The little creature quickly ran towards the lion’s trap that bound him and she gnawed the net with her sharp teeth until the net tore apart. Slowly she made a big hole in the net and soon the lion was able to free himself from the hunter’s trap.\n","\n","The lion thanked the little mouse for her help and the mouse reminded him that she had finally repaid the lion for sparing her life before. Thereafter, the lion and the mouse became good friends and lived happily in the forest. \"\"\"\n","\n","wrapper = textwrap.TextWrapper(width=150)\n","word_list = wrapper.wrap(text=text)\n","for element in word_list: \n","  print(element) "],"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":[" Once upon a time, there lived a lion in the dense Amazon rainforest. While he was sleeping by resting his big head on his paws, a tiny little mouse\n","unexpectedly crossed by and ran across the lion’s nose in haste. This woke up the lion and he laid his huge paw angrily on the tiny mouse to kill her.\n","The poor mouse begged the lion to spare her this time and she would pay him back on some other day. Hearing this, the lion was amused and wondered how\n","could such a tiny creature ever help him. But he was in a good mood and in his generosity he finally let the mouse go.  A few days later, a hunter set\n","a trap for the lion while the big animal was stalking for prey in the forest. Caught in the toils of a hunter’s net, the lion found it difficult to\n","free himself and roared loudly in anger.  As the mouse was passing by, she heard the roar and found the lion struggling hard to free himself from the\n","hunter’s net. The little creature quickly ran towards the lion’s trap that bound him and she gnawed the net with her sharp teeth until the net tore\n","apart. Slowly she made a big hole in the net and soon the lion was able to free himself from the hunter’s trap.  The lion thanked the little mouse for\n","her help and the mouse reminded him that she had finally repaid the lion for sparing her life before. Thereafter, the lion and the mouse became good\n","friends and lived happily in the forest.\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aSDB9XDd9YBu","executionInfo":{"status":"ok","timestamp":1679112132391,"user_tz":-330,"elapsed":1344,"user":{"displayName":"Ramsri Goutham","userId":"00967418115712089730"}},"outputId":"c0861b5d-4ee6-40b1-ea55-14d8fcc04162"},"source":["def get_keywords(text):\n","    out=[]\n","    try:\n","        # extractor = pke.unsupervised.MultipartiteRank()\n","        extractor = pke.unsupervised.YAKE()\n","        extractor.load_document(input=text,language='en')\n","        grammar = r\"\"\"\n","                NP:\n","                    {<NOUN|PROPN>+}\n","            \"\"\"\n","        extractor.ngram_selection(n=1)\n","        extractor.grammar_selection(grammar=grammar)\n","        # pos = {'VERB', 'ADJ', 'NOUN'}\n","        # pos ={'NOUN'}\n","        # stoplist = list(string.punctuation)\n","        # stoplist += ['-lrb-', '-rrb-', '-lcb-', '-rcb-', '-lsb-', '-rsb-']\n","        # stoplist += stopwords.words('english')\n","        # extractor.candidate_selection(n=1,pos=pos, stoplist=stoplist)\n","        extractor.candidate_selection(n=1)\n","\n","        extractor.candidate_weighting(window=3,\n","                                      use_stems=False)\n","\n","        keyphrases = extractor.get_n_best(n=30)\n","        \n","\n","        for val in keyphrases:\n","            out.append(val[0])\n","    except:\n","        out = []\n","        traceback.print_exc()\n","\n","    return out\n","\n","keywords = get_keywords(text)[:8]\n","print (\"keywords: \",keywords)"],"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["keywords:  ['lion', 'mouse', 'amazon', 'net', 'hunter', 'tiny', 'free', 'big']\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EO3owrXlWObz","executionInfo":{"status":"ok","timestamp":1679112135157,"user_tz":-330,"elapsed":421,"user":{"displayName":"Ramsri Goutham","userId":"00967418115712089730"}},"outputId":"17d45770-9091-4b5f-e111-743f1371c91e"},"source":["sentences = tokenize_sentences(text)\n","print (sentences)"],"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["['Once upon a time, there lived a lion in the dense Amazon rainforest.', 'While he was sleeping by resting his big head on his paws, a tiny little mouse unexpectedly crossed by and ran across the lion’s nose in haste.', 'This woke up the lion and he laid his huge paw angrily on the tiny mouse to kill her.', 'The poor mouse begged the lion to spare her this time and she would pay him back on some other day.', 'Hearing this, the lion was amused and wondered how could such a tiny creature ever help him.', 'But he was in a good mood and in his generosity he finally let the mouse go.', 'A few days later, a hunter set a trap for the lion while the big animal was stalking for prey in the forest.', 'Caught in the toils of a hunter’s net, the lion found it difficult to free himself and roared loudly in anger.', 'As the mouse was passing by, she heard the roar and found the lion struggling hard to free himself from the hunter’s net.', 'The little creature quickly ran towards the lion’s trap that bound him and she gnawed the net with her sharp teeth until the net tore apart.', 'Slowly she made a big hole in the net and soon the lion was able to free himself from the hunter’s trap.', 'The lion thanked the little mouse for her help and the mouse reminded him that she had finally repaid the lion for sparing her life before.', 'Thereafter, the lion and the mouse became good friends and lived happily in the forest.']\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tvjVX2dYWWNB","executionInfo":{"status":"ok","timestamp":1679112137896,"user_tz":-330,"elapsed":393,"user":{"displayName":"Ramsri Goutham","userId":"00967418115712089730"}},"outputId":"4ff6be82-fd92-4438-f057-628a3e890782"},"source":["from pprint import pprint\n","def get_sentences_for_keyword(keywords, sentences):\n","    keyword_processor = KeywordProcessor()\n","    keyword_sentences = {}\n","    for word in keywords:\n","        keyword_sentences[word] = []\n","        keyword_processor.add_keyword(word)\n","    for sentence in sentences:\n","        keywords_found = keyword_processor.extract_keywords(sentence)\n","        for key in keywords_found:\n","            keyword_sentences[key].append(sentence)\n","\n","    for key in keyword_sentences.keys():\n","        values = keyword_sentences[key]\n","        values = sorted(values, key=len, reverse=False)\n","        keyword_sentences[key] = values\n","    return keyword_sentences\n","\n","keyword_sentence_mapping = get_sentences_for_keyword(keywords, sentences)\n","pprint (keyword_sentence_mapping)"],"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["{'amazon': ['Once upon a time, there lived a lion in the dense Amazon '\n","            'rainforest.'],\n"," 'big': ['Slowly she made a big hole in the net and soon the lion was able to '\n","         'free himself from the hunter’s trap.',\n","         'A few days later, a hunter set a trap for the lion while the big '\n","         'animal was stalking for prey in the forest.',\n","         'While he was sleeping by resting his big head on his paws, a tiny '\n","         'little mouse unexpectedly crossed by and ran across the lion’s nose '\n","         'in haste.'],\n"," 'free': ['Slowly she made a big hole in the net and soon the lion was able to '\n","          'free himself from the hunter’s trap.',\n","          'Caught in the toils of a hunter’s net, the lion found it difficult '\n","          'to free himself and roared loudly in anger.',\n","          'As the mouse was passing by, she heard the roar and found the lion '\n","          'struggling hard to free himself from the hunter’s net.'],\n"," 'hunter': ['Slowly she made a big hole in the net and soon the lion was able '\n","            'to free himself from the hunter’s trap.',\n","            'A few days later, a hunter set a trap for the lion while the big '\n","            'animal was stalking for prey in the forest.',\n","            'Caught in the toils of a hunter’s net, the lion found it '\n","            'difficult to free himself and roared loudly in anger.',\n","            'As the mouse was passing by, she heard the roar and found the '\n","            'lion struggling hard to free himself from the hunter’s net.'],\n"," 'lion': ['Once upon a time, there lived a lion in the dense Amazon '\n","          'rainforest.',\n","          'This woke up the lion and he laid his huge paw angrily on the tiny '\n","          'mouse to kill her.',\n","          'Thereafter, the lion and the mouse became good friends and lived '\n","          'happily in the forest.',\n","          'Hearing this, the lion was amused and wondered how could such a '\n","          'tiny creature ever help him.',\n","          'The poor mouse begged the lion to spare her this time and she would '\n","          'pay him back on some other day.',\n","          'Slowly she made a big hole in the net and soon the lion was able to '\n","          'free himself from the hunter’s trap.',\n","          'A few days later, a hunter set a trap for the lion while the big '\n","          'animal was stalking for prey in the forest.',\n","          'Caught in the toils of a hunter’s net, the lion found it difficult '\n","          'to free himself and roared loudly in anger.',\n","          'As the mouse was passing by, she heard the roar and found the lion '\n","          'struggling hard to free himself from the hunter’s net.',\n","          'The lion thanked the little mouse for her help and the mouse '\n","          'reminded him that she had finally repaid the lion for sparing her '\n","          'life before.',\n","          'The lion thanked the little mouse for her help and the mouse '\n","          'reminded him that she had finally repaid the lion for sparing her '\n","          'life before.',\n","          'The little creature quickly ran towards the lion’s trap that bound '\n","          'him and she gnawed the net with her sharp teeth until the net tore '\n","          'apart.',\n","          'While he was sleeping by resting his big head on his paws, a tiny '\n","          'little mouse unexpectedly crossed by and ran across the lion’s nose '\n","          'in haste.'],\n"," 'mouse': ['But he was in a good mood and in his generosity he finally let the '\n","           'mouse go.',\n","           'This woke up the lion and he laid his huge paw angrily on the tiny '\n","           'mouse to kill her.',\n","           'Thereafter, the lion and the mouse became good friends and lived '\n","           'happily in the forest.',\n","           'The poor mouse begged the lion to spare her this time and she '\n","           'would pay him back on some other day.',\n","           'As the mouse was passing by, she heard the roar and found the lion '\n","           'struggling hard to free himself from the hunter’s net.',\n","           'The lion thanked the little mouse for her help and the mouse '\n","           'reminded him that she had finally repaid the lion for sparing her '\n","           'life before.',\n","           'The lion thanked the little mouse for her help and the mouse '\n","           'reminded him that she had finally repaid the lion for sparing her '\n","           'life before.',\n","           'While he was sleeping by resting his big head on his paws, a tiny '\n","           'little mouse unexpectedly crossed by and ran across the lion’s '\n","           'nose in haste.'],\n"," 'net': ['Slowly she made a big hole in the net and soon the lion was able to '\n","         'free himself from the hunter’s trap.',\n","         'Caught in the toils of a hunter’s net, the lion found it difficult '\n","         'to free himself and roared loudly in anger.',\n","         'As the mouse was passing by, she heard the roar and found the lion '\n","         'struggling hard to free himself from the hunter’s net.',\n","         'The little creature quickly ran towards the lion’s trap that bound '\n","         'him and she gnawed the net with her sharp teeth until the net tore '\n","         'apart.',\n","         'The little creature quickly ran towards the lion’s trap that bound '\n","         'him and she gnawed the net with her sharp teeth until the net tore '\n","         'apart.'],\n"," 'tiny': ['This woke up the lion and he laid his huge paw angrily on the tiny '\n","          'mouse to kill her.',\n","          'Hearing this, the lion was amused and wondered how could such a '\n","          'tiny creature ever help him.',\n","          'While he was sleeping by resting his big head on his paws, a tiny '\n","          'little mouse unexpectedly crossed by and ran across the lion’s nose '\n","          'in haste.']}\n"]}]},{"cell_type":"markdown","metadata":{"id":"neRbWQhO4GnG"},"source":["## Download pretrained BERT WSD Model - Run only once"]},{"cell_type":"markdown","metadata":{"id":"rELsk4JIMhJ3"},"source":["Download pre-trained BERT WSD from [here](https://entuedu-my.sharepoint.com/:f:/g/personal/boonpeng001_e_ntu_edu_sg/EiWzblOyyOBDtuO3klUbXoAB3THFzke-2MLWguIXrDopWg?e=08umXD)\n","\n","Click the download button at the top left of the link to download a file named \"bert_base-augmented-batch_size=128-lr=2e-5-max_gloss=6.zip\"\n","\n","Place the zip file in your Google drive home folder\n","\n","Original [BERT-WSD repository](https://github.com/BPYap/BERT-WSD). All credits to their awesome pre-trained model. "]},{"cell_type":"code","metadata":{"id":"MNz0zFZzrXqN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679112143241,"user_tz":-330,"elapsed":376,"user":{"displayName":"Ramsri Goutham","userId":"00967418115712089730"}},"outputId":"b51b376f-5ab5-46fe-a52a-a59e30599ea5"},"source":["import os\n","import zipfile\n","\n","bert_wsd_pytorch = \"/content/gdrive/My Drive/bert_base-augmented-batch_size=128-lr=2e-5-max_gloss=6.zip\"\n","extract_directory = \"/content/gdrive/My Drive\"\n","\n","extracted_folder = bert_wsd_pytorch.replace(\".zip\",\"\")\n","\n","#  If unzipped folder exists don't unzip again.\n","if not os.path.isdir(extracted_folder):\n","  with zipfile.ZipFile(bert_wsd_pytorch, 'r') as zip_ref:\n","      zip_ref.extractall(extract_directory)\n","else:\n","  print (extracted_folder,\" is extracted already\")"],"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/gdrive/My Drive/bert_base-augmented-batch_size=128-lr=2e-5-max_gloss=6  is extracted already\n"]}]},{"cell_type":"markdown","metadata":{"id":"_GtYSH2ewtO4"},"source":["# Run model"]},{"cell_type":"code","source":["!pip install sacremoses==0.0.53"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1nPXW7R_4kqg","executionInfo":{"status":"ok","timestamp":1679112185468,"user_tz":-330,"elapsed":5371,"user":{"displayName":"Ramsri Goutham","userId":"00967418115712089730"}},"outputId":"084be882-83c7-417b-8265-2afb9f10609b"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: sacremoses==0.0.53 in /usr/local/lib/python3.9/dist-packages (0.0.53)\n","Requirement already satisfied: regex in /usr/local/lib/python3.9/dist-packages (from sacremoses==0.0.53) (2022.10.31)\n","Requirement already satisfied: six in /usr/local/lib/python3.9/dist-packages (from sacremoses==0.0.53) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.9/dist-packages (from sacremoses==0.0.53) (8.1.3)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.9/dist-packages (from sacremoses==0.0.53) (1.1.1)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from sacremoses==0.0.53) (4.65.0)\n"]}]},{"cell_type":"code","metadata":{"id":"EnmszaP9zSpe","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679112200271,"user_tz":-330,"elapsed":11537,"user":{"displayName":"Ramsri Goutham","userId":"00967418115712089730"}},"outputId":"978e17d3-7d8c-43ba-d685-4cb1fcfc4200"},"source":["import torch\n","import math\n","from transformers import BertModel, BertConfig, BertPreTrainedModel, BertTokenizer\n","\n","class BertWSD(BertPreTrainedModel):\n","    def __init__(self, config):\n","        super().__init__(config)\n","\n","        self.bert = BertModel(config)\n","        self.dropout = torch.nn.Dropout(config.hidden_dropout_prob)\n","\n","        self.ranking_linear = torch.nn.Linear(config.hidden_size, 1)\n","\n","        self.init_weights()\n","\n","    \n","\n","DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model_dir = \"/content/gdrive/My Drive/bert_base-augmented-batch_size=128-lr=2e-5-max_gloss=6\"\n","\n","\n","model = BertWSD.from_pretrained(model_dir)\n","tokenizer = BertTokenizer.from_pretrained(model_dir)\n","# add new special token\n","if '[TGT]' not in tokenizer.additional_special_tokens:\n","    tokenizer.add_special_tokens({'additional_special_tokens': ['[TGT]']})\n","    assert '[TGT]' in tokenizer.additional_special_tokens\n","    model.resize_token_embeddings(len(tokenizer))\n","    \n","model.to(DEVICE)\n","model.eval()"],"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["BertWSD(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(30523, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (ranking_linear): Linear(in_features=768, out_features=1, bias=True)\n",")"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"I0bWxo4vFUfH","executionInfo":{"status":"ok","timestamp":1679112205042,"user_tz":-330,"elapsed":381,"user":{"displayName":"Ramsri Goutham","userId":"00967418115712089730"}},"outputId":"7fc0c148-0ac7-4656-c742-eec9753d928c"},"source":["import csv\n","import os\n","from collections import namedtuple\n","\n","import nltk\n","nltk.download('wordnet')\n","from nltk.corpus import wordnet as wn\n","\n","import torch\n","import re\n","import time\n","import torch\n","from tabulate import tabulate\n","from torch.nn.functional import softmax\n","from tqdm import tqdm\n","from transformers import BertTokenizer\n","\n","GlossSelectionRecord = namedtuple(\"GlossSelectionRecord\", [\"guid\", \"sentence\", \"sense_keys\", \"glosses\", \"targets\"])\n","BertInput = namedtuple(\"BertInput\", [\"input_ids\", \"input_mask\", \"segment_ids\", \"label_id\"])\n","\n","MAX_SEQ_LENGTH = 128\n","\n","def _create_features_from_records(records, max_seq_length, tokenizer, cls_token_at_end=False, pad_on_left=False,\n","                                  cls_token='[CLS]', sep_token='[SEP]', pad_token=0,\n","                                  sequence_a_segment_id=0, sequence_b_segment_id=1,\n","                                  cls_token_segment_id=1, pad_token_segment_id=0,\n","                                  mask_padding_with_zero=True, disable_progress_bar=False):\n","    \"\"\" Convert records to list of features. Each feature is a list of sub-features where the first element is\n","        always the feature created from context-gloss pair while the rest of the elements are features created from\n","        context-example pairs (if available)\n","        `cls_token_at_end` define the location of the CLS token:\n","            - False (Default, BERT/XLM pattern): [CLS] + A + [SEP] + B + [SEP]\n","            - True (XLNet/GPT pattern): A + [SEP] + B + [SEP] + [CLS]\n","        `cls_token_segment_id` define the segment id associated to the CLS token (0 for BERT, 2 for XLNet)\n","    \"\"\"\n","    features = []\n","    for record in tqdm(records, disable=disable_progress_bar):\n","        tokens_a = tokenizer.tokenize(record.sentence)\n","\n","        sequences = [(gloss, 1 if i in record.targets else 0) for i, gloss in enumerate(record.glosses)]\n","\n","        pairs = []\n","        for seq, label in sequences:\n","            tokens_b = tokenizer.tokenize(seq)\n","\n","            # Modifies `tokens_a` and `tokens_b` in place so that the total\n","            # length is less than the specified length.\n","            # Account for [CLS], [SEP], [SEP] with \"- 3\"\n","            _truncate_seq_pair(tokens_a, tokens_b, max_seq_length - 3)\n","\n","            # The convention in BERT is:\n","            # (a) For sequence pairs:\n","            #  tokens:   [CLS] is this jack ##son ##ville ? [SEP] no it is not . [SEP]\n","            #  type_ids:   0   0  0    0    0     0       0   0   1  1  1  1   1   1\n","            #\n","            # Where \"type_ids\" are used to indicate whether this is the first\n","            # sequence or the second sequence. The embedding vectors for `type=0` and\n","            # `type=1` were learned during pre-training and are added to the wordpiece\n","            # embedding vector (and position vector). This is not *strictly* necessary\n","            # since the [SEP] token unambiguously separates the sequences, but it makes\n","            # it easier for the model to learn the concept of sequences.\n","            #\n","            # For classification tasks, the first vector (corresponding to [CLS]) is\n","            # used as as the \"sentence vector\". Note that this only makes sense because\n","            # the entire model is fine-tuned.\n","            tokens = tokens_a + [sep_token]\n","            segment_ids = [sequence_a_segment_id] * len(tokens)\n","\n","            tokens += tokens_b + [sep_token]\n","            segment_ids += [sequence_b_segment_id] * (len(tokens_b) + 1)\n","\n","            if cls_token_at_end:\n","                tokens = tokens + [cls_token]\n","                segment_ids = segment_ids + [cls_token_segment_id]\n","            else:\n","                tokens = [cls_token] + tokens\n","                segment_ids = [cls_token_segment_id] + segment_ids\n","\n","            input_ids = tokenizer.convert_tokens_to_ids(tokens)\n","\n","            # The mask has 1 for real tokens and 0 for padding tokens. Only real\n","            # tokens are attended to.\n","            input_mask = [1 if mask_padding_with_zero else 0] * len(input_ids)\n","\n","            # Zero-pad up to the sequence length.\n","            padding_length = max_seq_length - len(input_ids)\n","            if pad_on_left:\n","                input_ids = ([pad_token] * padding_length) + input_ids\n","                input_mask = ([0 if mask_padding_with_zero else 1] * padding_length) + input_mask\n","                segment_ids = ([pad_token_segment_id] * padding_length) + segment_ids\n","            else:\n","                input_ids = input_ids + ([pad_token] * padding_length)\n","                input_mask = input_mask + ([0 if mask_padding_with_zero else 1] * padding_length)\n","                segment_ids = segment_ids + ([pad_token_segment_id] * padding_length)\n","\n","            assert len(input_ids) == max_seq_length\n","            assert len(input_mask) == max_seq_length\n","            assert len(segment_ids) == max_seq_length\n","\n","            pairs.append(\n","                BertInput(input_ids=input_ids, input_mask=input_mask, segment_ids=segment_ids, label_id=label)\n","            )\n","\n","        features.append(pairs)\n","\n","    return features\n","\n","\n","def _truncate_seq_pair(tokens_a, tokens_b, max_length):\n","    \"\"\"Truncates a sequence pair in place to the maximum length.\"\"\"\n","\n","    # This is a simple heuristic which will always truncate the longer sequence\n","    # one token at a time. This makes more sense than truncating an equal percent\n","    # of tokens from each, since if one sequence is very short then each token\n","    # that's truncated likely contains more information than a longer sequence.\n","    while True:\n","        total_length = len(tokens_a) + len(tokens_b)\n","        if total_length <= max_length:\n","            break\n","        if len(tokens_a) > len(tokens_b):\n","            tokens_a.pop()\n","        else:\n","            tokens_b.pop()"],"execution_count":13,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZKbPKBjr-KTp","executionInfo":{"status":"ok","timestamp":1679112213516,"user_tz":-330,"elapsed":2057,"user":{"displayName":"Ramsri Goutham","userId":"00967418115712089730"}},"outputId":"87a7cdb5-c66e-4f4b-8fc5-d7c4f6c50233"},"source":["from pprint import pprint\n","nltk.download('omw-1.4')\n","sentence = \"Mark's favourite game is **Cricket**.\"\n","\n","sentence_for_bert = sentence.replace(\"**\",\" [TGT] \")\n","sentence_for_bert = \" \".join(sentence_for_bert.split())\n","\n","print (sentence_for_bert)\n","\n","re_result = re.search(r\"\\[TGT\\](.*)\\[TGT\\]\", sentence_for_bert)\n","if re_result is None:\n","    print(\"\\nIncorrect input format. Please try again.\")\n","\n","ambiguous_word = re_result.group(1).strip()\n","\n","print (\"Word: \",ambiguous_word)\n","\n","\n","results = dict()\n","\n","# wn_pos = wn.NOUN\n","# for i, synset in enumerate(set(wn.synsets(ambiguous_word, pos=wn_pos))):\n","for i, synset in enumerate(set(wn.synsets(ambiguous_word))):\n","    results[synset] =  synset.definition()\n","\n","pprint (results)\n","\n","sense_keys=[]\n","definitions=[]\n","for sense_key, definition in results.items():\n","    sense_keys.append(sense_key)\n","    definitions.append(definition)\n","\n","\n","print (sense_keys)\n","print (definitions)\n","\n","\n","record = GlossSelectionRecord(\"test\", sentence_for_bert, sense_keys, definitions, [-1])"],"execution_count":14,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"]},{"output_type":"stream","name":"stdout","text":["Mark's favourite game is [TGT] Cricket [TGT] .\n","Word:  Cricket\n","{Synset('cricket.n.01'): 'leaping insect; male makes chirping noises by '\n","                         'rubbing the forewings together',\n"," Synset('cricket.n.02'): 'a game played with a ball and bat by two teams of 11 '\n","                         'players; teams take turns trying to score runs',\n"," Synset('cricket.v.01'): 'play cricket'}\n","[Synset('cricket.v.01'), Synset('cricket.n.02'), Synset('cricket.n.01')]\n","['play cricket', 'a game played with a ball and bat by two teams of 11 players; teams take turns trying to score runs', 'leaping insect; male makes chirping noises by rubbing the forewings together']\n"]}]},{"cell_type":"code","source":["model.config.vocab_size"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PtZDDEUCrVRl","executionInfo":{"status":"ok","timestamp":1679112217541,"user_tz":-330,"elapsed":392,"user":{"displayName":"Ramsri Goutham","userId":"00967418115712089730"}},"outputId":"5fa77f11-e107-410a-839f-51b3acae0593"},"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["30523"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ix16JsX7fyt1","executionInfo":{"status":"ok","timestamp":1679112221167,"user_tz":-330,"elapsed":365,"user":{"displayName":"Ramsri Goutham","userId":"00967418115712089730"}},"outputId":"95f232d8-ee08-47f2-9f44-b62c76290f68"},"source":["features = _create_features_from_records([record], MAX_SEQ_LENGTH, tokenizer,\n","                                          cls_token=tokenizer.cls_token,\n","                                          sep_token=tokenizer.sep_token,\n","                                          cls_token_segment_id=1,\n","                                          pad_token_segment_id=0,\n","                                          disable_progress_bar=True)[0]\n","\n","print (len(features))\n","\n","for ftr in features:\n","  print (tokenizer.convert_ids_to_tokens(ftr.input_ids))\n"],"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["3\n","['[CLS]', 'mark', \"'\", 's', 'favourite', 'game', 'is', '[UNK]', 'cricket', '[UNK]', '.', '[SEP]', 'play', 'cricket', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n","['[CLS]', 'mark', \"'\", 's', 'favourite', 'game', 'is', '[UNK]', 'cricket', '[UNK]', '.', '[SEP]', 'a', 'game', 'played', 'with', 'a', 'ball', 'and', 'bat', 'by', 'two', 'teams', 'of', '11', 'players', ';', 'teams', 'take', 'turns', 'trying', 'to', 'score', 'runs', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n","['[CLS]', 'mark', \"'\", 's', 'favourite', 'game', 'is', '[UNK]', 'cricket', '[UNK]', '.', '[SEP]', 'leaping', 'insect', ';', 'male', 'makes', 'chi', '##rp', '##ing', 'noises', 'by', 'rubbing', 'the', 'forewings', 'together', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Aucvx7VAEhj-","executionInfo":{"status":"ok","timestamp":1679112225925,"user_tz":-330,"elapsed":1670,"user":{"displayName":"Ramsri Goutham","userId":"00967418115712089730"}},"outputId":"f2b133dd-52ec-4891-84f3-7a616ba2c336"},"source":["with torch.no_grad():\n","      logits = torch.zeros(len(definitions), dtype=torch.double).to(DEVICE)\n","      for i, bert_input in list(enumerate(features)):\n","          logits[i] = model.ranking_linear(\n","              model.bert(\n","                  input_ids=torch.tensor(bert_input.input_ids, dtype=torch.long).unsqueeze(0).to(DEVICE),\n","                  attention_mask=torch.tensor(bert_input.input_mask, dtype=torch.long).unsqueeze(0).to(DEVICE),\n","                  token_type_ids=torch.tensor(bert_input.segment_ids, dtype=torch.long).unsqueeze(0).to(DEVICE)\n","              )[1]\n","          )\n","      scores = softmax(logits, dim=0)\n","\n","      preds = (sorted(zip(sense_keys, definitions, scores), key=lambda x: x[-1], reverse=True))\n","\n","print (\"\\n\")\n","for pred in preds:\n","  print (pred)\n","sense = preds[0][0]\n","meaning = preds[0][1]\n","\n","print (\"\\nMost appropriate sense: \",sense)\n","print (\"Most appropriate meaning: \",meaning)"],"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","(Synset('cricket.n.02'), 'a game played with a ball and bat by two teams of 11 players; teams take turns trying to score runs', tensor(0.6093, dtype=torch.float64))\n","(Synset('cricket.v.01'), 'play cricket', tensor(0.3907, dtype=torch.float64))\n","(Synset('cricket.n.01'), 'leaping insect; male makes chirping noises by rubbing the forewings together', tensor(9.1672e-06, dtype=torch.float64))\n","\n","Most appropriate sense:  Synset('cricket.n.02')\n","Most appropriate meaning:  a game played with a ball and bat by two teams of 11 players; teams take turns trying to score runs\n"]}]},{"cell_type":"code","metadata":{"id":"wJSpZRuOF-52","executionInfo":{"status":"ok","timestamp":1679112230857,"user_tz":-330,"elapsed":398,"user":{"displayName":"Ramsri Goutham","userId":"00967418115712089730"}}},"source":["def get_sense(sent):\n","  re_result = re.search(r\"\\[TGT\\](.*)\\[TGT\\]\", sent)\n","  if re_result is None:\n","      print(\"\\nIncorrect input format. Please try again.\")\n","\n","  ambiguous_word = re_result.group(1).strip()\n","  results = dict()\n","\n","  for i, synset in enumerate(set(wn.synsets(ambiguous_word))):\n","      results[synset] =  synset.definition()\n","\n","  if len(results) ==0:\n","    return None\n","\n","  sense_keys=[]\n","  definitions=[]\n","  for sense_key, definition in results.items():\n","      sense_keys.append(sense_key)\n","      definitions.append(definition)\n","\n","  record = GlossSelectionRecord(\"test\", sent, sense_keys, definitions, [-1])\n","\n","  features = _create_features_from_records([record], MAX_SEQ_LENGTH, tokenizer,\n","                                            cls_token=tokenizer.cls_token,\n","                                            sep_token=tokenizer.sep_token,\n","                                            cls_token_segment_id=1,\n","                                            pad_token_segment_id=0,\n","                                            disable_progress_bar=True)[0]\n","\n","  with torch.no_grad():\n","      logits = torch.zeros(len(definitions), dtype=torch.double).to(DEVICE)\n","      for i, bert_input in list(enumerate(features)):\n","          logits[i] = model.ranking_linear(\n","              model.bert(\n","                  input_ids=torch.tensor(bert_input.input_ids, dtype=torch.long).unsqueeze(0).to(DEVICE),\n","                  attention_mask=torch.tensor(bert_input.input_mask, dtype=torch.long).unsqueeze(0).to(DEVICE),\n","                  token_type_ids=torch.tensor(bert_input.segment_ids, dtype=torch.long).unsqueeze(0).to(DEVICE)\n","              )[1]\n","          )\n","      scores = softmax(logits, dim=0)\n","\n","      preds = (sorted(zip(sense_keys, definitions, scores), key=lambda x: x[-1], reverse=True))\n","\n","  sense = preds[0][0]\n","  meaning = preds[0][1]\n","  return sense\n"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"v2aOpD1WASMl","executionInfo":{"status":"ok","timestamp":1679112336295,"user_tz":-330,"elapsed":101958,"user":{"displayName":"Ramsri Goutham","userId":"00967418115712089730"}},"outputId":"2c50ab11-3312-4371-97dd-9c54f8392b50"},"source":["import statistics \n","from statistics import mode \n","import re\n","\n","def get_synsets_for_word (word):\n","  return set(wn.synsets(word))\n","  \n","keyword_best_sense = {}\n","\n","for keyword in  keyword_sentence_mapping:\n","  print (\"\\n\\n\")\n","  print(\"Original word: \",keyword)\n","  try:\n","    identified_synsets=get_synsets_for_word(keyword)\n","  except:\n","    continue\n","  for synset in identified_synsets:\n","    print (synset,\"   \",synset.definition())\n","  top_3_sentences = keyword_sentence_mapping[keyword][:3]\n","  best_senses=[]\n","  for sent in top_3_sentences:\n","    insensitive_keyword = re.compile(re.escape(keyword), re.IGNORECASE)\n","    modified_sentence = insensitive_keyword.sub(\" [TGT] \"+keyword+\" [TGT] \", sent,count=1)\n","    modified_sentence = \" \".join(modified_sentence.split())\n","    print (\"modified sentence \",modified_sentence)\n","    best_sense = get_sense(modified_sentence)\n","    best_senses.append(best_sense)\n","  best_sense = mode(best_senses)\n","  print (\"Best sense: \",best_sense)\n","  defn = best_sense.definition()\n","  print (defn)\n","  keyword_best_sense [keyword] = defn"],"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","\n","Original word:  lion\n","Synset('leo.n.03')     the fifth sign of the zodiac; the sun is in this sign from about July 23 to August 22\n","Synset('lion.n.01')     large gregarious predatory feline of Africa and India having a tawny coat with a shaggy mane in the male\n","Synset('lion.n.02')     a celebrity who is lionized (much sought after)\n","Synset('leo.n.01')     (astrology) a person who is born while the sun is in Leo\n","modified sentence  Once upon a time, there lived a [TGT] lion [TGT] in the dense Amazon rainforest.\n","modified sentence  This woke up the [TGT] lion [TGT] and he laid his huge paw angrily on the tiny mouse to kill her.\n","modified sentence  Thereafter, the [TGT] lion [TGT] and the mouse became good friends and lived happily in the forest.\n","Best sense:  Synset('lion.n.01')\n","large gregarious predatory feline of Africa and India having a tawny coat with a shaggy mane in the male\n","\n","\n","\n","Original word:  mouse\n","Synset('mouse.v.02')     manipulate the mouse of a computer\n","Synset('mouse.n.04')     a hand-operated electronic device that controls the coordinates of a cursor on your computer screen as you move it around on a pad; on the bottom of the device is a ball that rolls on the surface of the pad\n","Synset('mouse.n.01')     any of numerous small rodents typically resembling diminutive rats having pointed snouts and small ears on elongated bodies with slender usually hairless tails\n","Synset('mouse.n.03')     person who is quiet or timid\n","Synset('sneak.v.01')     to go stealthily or furtively\n","Synset('shiner.n.01')     a swollen bruise caused by a blow to the eye\n","modified sentence  But he was in a good mood and in his generosity he finally let the [TGT] mouse [TGT] go.\n","modified sentence  This woke up the lion and he laid his huge paw angrily on the tiny [TGT] mouse [TGT] to kill her.\n","modified sentence  Thereafter, the lion and the [TGT] mouse [TGT] became good friends and lived happily in the forest.\n","Best sense:  Synset('mouse.n.01')\n","any of numerous small rodents typically resembling diminutive rats having pointed snouts and small ears on elongated bodies with slender usually hairless tails\n","\n","\n","\n","Original word:  amazon\n","Synset('amazon.n.02')     (Greek mythology) one of a nation of women warriors of Scythia (who burned off the right breast in order to use a bow and arrow more effectively)\n","Synset('amazon.n.04')     mainly green tropical American parrots\n","Synset('amazon.n.01')     a large strong and aggressive woman\n","Synset('amazon.n.03')     a major South American river; arises in the Andes and flows eastward into the South Atlantic; the world's 2nd longest river (4000 miles)\n","modified sentence  Once upon a time, there lived a lion in the dense [TGT] amazon [TGT] rainforest.\n","Best sense:  Synset('amazon.n.03')\n","a major South American river; arises in the Andes and flows eastward into the South Atlantic; the world's 2nd longest river (4000 miles)\n","\n","\n","\n","Original word:  net\n","Synset('net.a.01')     remaining after all deductions\n","Synset('net.v.01')     make as a net profit\n","Synset('net_income.n.01')     the excess of revenues over outlays in a given period of time (including depreciation and other non-cash expenses)\n","Synset('net.v.04')     catch with a net\n","Synset('net.n.04')     a goal lined with netting (as in soccer or hockey)\n","Synset('web.v.01')     construct or form a web, as if by weaving\n","Synset('net.v.02')     yield as a net profit\n","Synset('net.n.02')     a trap made of netting to catch fish or birds or insects\n","Synset('net.n.05')     game equipment consisting of a strip of netting dividing the playing area in tennis or badminton\n","Synset('final.s.02')     conclusive in a process or progression\n","Synset('internet.n.01')     a computer network consisting of a worldwide network of computer networks that use the TCP/IP network protocols to facilitate data transmission and exchange\n","Synset('net.n.06')     an open fabric of string or rope or wire woven together at regular intervals\n","modified sentence  Slowly she made a big hole in the [TGT] net [TGT] and soon the lion was able to free himself from the hunter’s trap.\n","modified sentence  Caught in the toils of a hunter’s [TGT] net [TGT] , the lion found it difficult to free himself and roared loudly in anger.\n","modified sentence  As the mouse was passing by, she heard the roar and found the lion struggling hard to free himself from the hunter’s [TGT] net [TGT] .\n","Best sense:  Synset('net.n.02')\n","a trap made of netting to catch fish or birds or insects\n","\n","\n","\n","Original word:  hunter\n","Synset('hunter.n.04')     a watch with a hinged metal lid to protect the crystal\n","Synset('hunter.n.01')     someone who hunts game\n","Synset('orion.n.02')     a constellation on the equator to the east of Taurus; contains Betelgeuse and Rigel\n","Synset('hunter.n.02')     a person who searches for something\n","modified sentence  Slowly she made a big hole in the net and soon the lion was able to free himself from the [TGT] hunter [TGT] ’s trap.\n","modified sentence  A few days later, a [TGT] hunter [TGT] set a trap for the lion while the big animal was stalking for prey in the forest.\n","modified sentence  Caught in the toils of a [TGT] hunter [TGT] ’s net, the lion found it difficult to free himself and roared loudly in anger.\n","Best sense:  Synset('hunter.n.01')\n","someone who hunts game\n","\n","\n","\n","Original word:  tiny\n","Synset('bantam.s.01')     very small\n","modified sentence  This woke up the lion and he laid his huge paw angrily on the [TGT] tiny [TGT] mouse to kill her.\n","modified sentence  Hearing this, the lion was amused and wondered how could such a [TGT] tiny [TGT] creature ever help him.\n","modified sentence  While he was sleeping by resting his big head on his paws, a [TGT] tiny [TGT] little mouse unexpectedly crossed by and ran across the lion’s nose in haste.\n","Best sense:  Synset('bantam.s.01')\n","very small\n","\n","\n","\n","Original word:  free\n","Synset('release.v.08')     part with a possession or right\n","Synset('spare.s.03')     not taken up by scheduled activities\n","Synset('free.a.01')     able to act at will; not hampered; not under compulsion or restraint\n","Synset('absolve.v.02')     let off the hook\n","Synset('rid.v.01')     relieve from\n","Synset('unblock.v.03')     make (assets) available\n","Synset('free.a.06')     not held in servitude\n","Synset('free.n.01')     people who are free\n","Synset('free.a.02')     unconstrained or not chemically bound in a molecule or not fixed and capable of relatively unrestricted motion\n","Synset('complimentary.s.02')     costing nothing\n","Synset('free.v.07')     free or remove obstruction from\n","Synset('loose.r.01')     without restraint\n","Synset('detached.s.06')     not fixed in position\n","Synset('barren.s.03')     completely wanting or lacking\n","Synset('dislodge.v.01')     remove or force out from a position\n","Synset('release.v.09')     release (gas or energy) as a result of a chemical reaction or physical decomposition\n","Synset('free.v.01')     grant freedom to; free from confinement\n","Synset('exempt.v.01')     grant relief or an exemption from a rule or requirement to\n","Synset('free.v.06')     free from obligations or duties\n","Synset('free.v.05')     make (information) available for publication\n","Synset('free.s.09')     not literal\n","Synset('free.s.04')     not occupied or in use\n","modified sentence  Slowly she made a big hole in the net and soon the lion was able to [TGT] free [TGT] himself from the hunter’s trap.\n","modified sentence  Caught in the toils of a hunter’s net, the lion found it difficult to [TGT] free [TGT] himself and roared loudly in anger.\n","modified sentence  As the mouse was passing by, she heard the roar and found the lion struggling hard to [TGT] free [TGT] himself from the hunter’s net.\n","Best sense:  Synset('free.a.01')\n","able to act at will; not hampered; not under compulsion or restraint\n","\n","\n","\n","Original word:  big\n","Synset('big.s.05')     conspicuous in position or importance\n","Synset('big.s.08')     feeling self-importance\n","Synset('big.s.10')     marked by intense physical force\n","Synset('big.s.13')     in an advanced stage of pregnancy\n","Synset('big.r.01')     extremely well\n","Synset('big.s.04')     loud and firm\n","Synset('big.r.03')     on a grand scale\n","Synset('big.r.04')     in a major way\n","Synset('big.s.06')     prodigious\n","Synset('adult.s.01')     (of animals) fully developed\n","Synset('boastful.s.01')     exhibiting self-importance\n","Synset('big.s.11')     generous and understanding and tolerant\n","Synset('big.s.12')     given or giving freely\n","Synset('boastfully.r.01')     in a boastful manner\n","Synset('big.s.02')     significant\n","Synset('large.a.01')     above average in size or number or quantity or magnitude or extent\n","Synset('bad.s.02')     very intense\n","modified sentence  Slowly she made a [TGT] big [TGT] hole in the net and soon the lion was able to free himself from the hunter’s trap.\n","modified sentence  A few days later, a hunter set a trap for the lion while the [TGT] big [TGT] animal was stalking for prey in the forest.\n","modified sentence  While he was sleeping by resting his [TGT] big [TGT] head on his paws, a tiny little mouse unexpectedly crossed by and ran across the lion’s nose in haste.\n","Best sense:  Synset('large.a.01')\n","above average in size or number or quantity or magnitude or extent\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ypSVwXu7eoA3","executionInfo":{"status":"ok","timestamp":1679112336296,"user_tz":-330,"elapsed":50,"user":{"displayName":"Ramsri Goutham","userId":"00967418115712089730"}},"outputId":"e038099a-d0eb-42e4-c118-ec17443f0421"},"source":["pprint (keyword_best_sense)\n","\n","# {'amazon': 'a major South American river; arises in the Andes and flows '\n","#            \"eastward into the South Atlantic; the world's 2nd longest river \"\n","#            '(4000 miles)',\n","#  'big': 'above average in size or number or quantity or magnitude or extent',\n","#  'free': 'able to act at will; not hampered; not under compulsion or restraint',\n","#  'hunter': 'someone who hunts game',\n","#  'lion': 'large gregarious predatory feline of Africa and India having a tawny '\n","#          'coat with a shaggy mane in the male',\n","#  'mouse': 'any of numerous small rodents typically resembling diminutive rats '\n","#           'having pointed snouts and small ears on elongated bodies with '\n","#           'slender usually hairless tails',\n","#  'net': 'a trap made of netting to catch fish or birds or insects',\n","#  'tiny': 'very small'}"],"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["{'amazon': 'a major South American river; arises in the Andes and flows '\n","           \"eastward into the South Atlantic; the world's 2nd longest river \"\n","           '(4000 miles)',\n"," 'big': 'above average in size or number or quantity or magnitude or extent',\n"," 'free': 'able to act at will; not hampered; not under compulsion or restraint',\n"," 'hunter': 'someone who hunts game',\n"," 'lion': 'large gregarious predatory feline of Africa and India having a tawny '\n","         'coat with a shaggy mane in the male',\n"," 'mouse': 'any of numerous small rodents typically resembling diminutive rats '\n","          'having pointed snouts and small ears on elongated bodies with '\n","          'slender usually hairless tails',\n"," 'net': 'a trap made of netting to catch fish or birds or insects',\n"," 'tiny': 'very small'}\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z1ZAzdJZZH7h","executionInfo":{"status":"ok","timestamp":1679112336298,"user_tz":-330,"elapsed":49,"user":{"displayName":"Ramsri Goutham","userId":"00967418115712089730"}},"outputId":"81664876-e5a5-4fd1-b3a2-9e7eb9ac420b"},"source":["import random \n","from prettytable import PrettyTable\n","x = PrettyTable()\n","all_keywords= list(keyword_best_sense.keys())\n","all_definitions = list(keyword_best_sense.values())\n","random.shuffle(all_keywords)\n","random.shuffle(all_definitions)\n","print (all_keywords)\n","print (all_definitions)"],"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["['lion', 'tiny', 'hunter', 'free', 'big', 'net', 'mouse', 'amazon']\n","['a trap made of netting to catch fish or birds or insects', 'above average in size or number or quantity or magnitude or extent', \"a major South American river; arises in the Andes and flows eastward into the South Atlantic; the world's 2nd longest river (4000 miles)\", 'able to act at will; not hampered; not under compulsion or restraint', 'someone who hunts game', 'very small', 'any of numerous small rodents typically resembling diminutive rats having pointed snouts and small ears on elongated bodies with slender usually hairless tails', 'large gregarious predatory feline of Africa and India having a tawny coat with a shaggy mane in the male']\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":261},"id":"sVIdVRmDjcxn","executionInfo":{"status":"ok","timestamp":1679112336299,"user_tz":-330,"elapsed":45,"user":{"displayName":"Ramsri Goutham","userId":"00967418115712089730"}},"outputId":"79d200b0-5cf1-48ae-9cf6-9215b5b1a355"},"source":["from IPython.display import Markdown, display\n","def printmd(string):\n","    display(Markdown(string))\n","\n","x.field_names=['Word', \"Definition\"]\n","for word,defn in zip(all_keywords,all_definitions):\n","  x.add_row([word,defn])\n","\n","printmd(\"**Match the following words to their correct meanings.**\")\n","# print (\"\\n\")\n","print (x)"],"execution_count":22,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"**Match the following words to their correct meanings.**"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["+--------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","|  Word  |                                                                            Definition                                                                           |\n","+--------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","|  lion  |                                                     a trap made of netting to catch fish or birds or insects                                                    |\n","|  tiny  |                                                above average in size or number or quantity or magnitude or extent                                               |\n","| hunter |             a major South American river; arises in the Andes and flows eastward into the South Atlantic; the world's 2nd longest river (4000 miles)            |\n","|  free  |                                               able to act at will; not hampered; not under compulsion or restraint                                              |\n","|  big   |                                                                      someone who hunts game                                                                     |\n","|  net   |                                                                            very small                                                                           |\n","| mouse  | any of numerous small rodents typically resembling diminutive rats having pointed snouts and small ears on elongated bodies with slender usually hairless tails |\n","| amazon |                             large gregarious predatory feline of Africa and India having a tawny coat with a shaggy mane in the male                            |\n","+--------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"]}]}]}